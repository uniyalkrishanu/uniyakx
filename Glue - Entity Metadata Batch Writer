import sys
import json
import csv
import boto3
from boto3.dynamodb.conditions import Key
from awsglue.utils import getResolvedOptions
from pyspark.sql.session import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import input_file_name, col, when, to_date
from pyspark.sql.types import Row
from datetime import datetime
from pytz import timezone

#CONFIGURATIONS and other parameters
args = getResolvedOptions(sys.argv, ['ENTITY_RUN_CONFIG', 'ENTITY_PROCESSING_CONFIG', 'SOURCE_BUCKET'])
entity_run_config_path = args['ENTITY_RUN_CONFIG']#'/config/aegon_datalake/indexing_pipeline_dt.entityrunconfig'#
entity_processing_config_path = args['ENTITY_PROCESSING_CONFIG']#'/config/aegon_datalake/indexing_pipeline_dt.entityprocessconfig'#
s3BucketName = args['SOURCE_BUCKET']#'aegon-raw-datalake-store-dt'#

spark = SparkSession.builder.getOrCreate()
dynamodb = boto3.resource('dynamodb', region_name="ap-south-1")

class Configuration:
    def __init__(self):
        self.configTbl = None
        self.response = None
        self.response_list = []
        self.ConfigDict = {}
    def fetch_run_config(self):
        self.configTbl = dynamodb.Table('DatalakeIndexerConfig-dt')
        self.response = self.configTbl.query(IndexName='active-index',KeyConditionExpression=Key('active').eq('true'))
        self.response_list = self.response['Items']
        self.ConfigDict = {item['entity']:item for item in self.response_list}
        return self.ConfigDict

class DynamoIndexBuilder:
    
    def __init__(self):
        self.dynamoDB_schema = StructType([
            StructField('entity_id', StringType(),True),
            StructField('created_at', StringType(), True),
            StructField('s3_key', StringType(), True)])
        
    def getID(self, uniqueCol, payload, targetentity):
        id = uniqueCol.split('.')
        if targetentity == 'suspenses':
            for key in id:
                if isinstance(payload, list):
                    payload = payload[0][key]
                elif isinstance(payload, dict):
                    payload = payload[key]
        else:
            for key in id:
                payload = payload[key]
        return payload
        
    def getRows(self, row, uniqueCol, targetentity):
        payload_dynamo = {}
        payload_entity = row.asDict()
        payload_dynamo['entity_id'] = self.getID(uniqueCol, payload_entity, targetentity)    
        payload_dynamo['created_at'] = payload_entity.get('created_at')
        payload_dynamo['s3_key'] = payload_entity.get('s3_key')
        payload_dynamo['s3_key'] = payload_dynamo['s3_key'][payload_dynamo['s3_key'].index('/',5)+1:]
        return Row(**payload_dynamo)
        
    def dynamotablebuild(self, entityDF_dynamo, entityDF, attributeCol, uniqueCol, targetentity):
        if targetentity != 'suspenses':
            schemaList = [uniqueCol, 'created_at'] + attributeCol
            if targetentity == 'payment' or targetentity == 'issuance-task':
                uniqueCol = uniqueCol.split('.')[1]
            if targetentity == 'policy' and 'businessTransactionDate' in entityDF.columns:
                schemaList = schemaList + ['businessTransactionDate']
                entityDF = entityDF.select(schemaList)
            else:
                entityDF = entityDF.select(schemaList)
            entityDF.printSchema()    
            entityDF = entityDF.withColumn('created_at1', entityDF.created_at)
            entityDF = entityDF.drop(*['created_at'])
            DynamoTbl = entityDF_dynamo.join(entityDF,(entityDF_dynamo.entity_id == entityDF[uniqueCol]) & (entityDF_dynamo.created_at == entityDF.created_at1)).drop_duplicates()
            DynamoTbl = DynamoTbl.drop(*['created_at1', uniqueCol])
            if targetentity == 'policy' and 'businessTransactionDate' in entityDF.columns:
                DynamoTbl = DynamoTbl.withColumn('businessTransactionDate', when(DynamoTbl['businessTransactionDate'].isNull(), DynamoTbl.created_at).otherwise(DynamoTbl['businessTransactionDate']))
            elif targetentity == 'policy' and 'businessTransactionDate' not in entityDF.columns:
                DynamoTbl = DynamoTbl.withColumn('businessTransactionDate', DynamoTbl.created_at)            
        else:
            DynamoTbl = entityDF_dynamo
        return DynamoTbl
         

def processEntity(raw_bucket, sourceentity, targetentity, dynamotable, uniqueCol, attributeCol, year, startDate, endDate):
    entityDF = spark.read.json("s3://"+s3BucketName+"/"+sourceentity+"/year="+year)
    entityDF = entityDF.filter(to_date(col('created_at')).between(startDate, endDate))
    print('entityDF_dynamo_count', entityDF.count())
    entityDF = entityDF.withColumn('s3_key', input_file_name())
    entityDF_dynamo_rdd = entityDF.rdd.map(lambda x: dynamo_obj.getRows(x, uniqueCol, targetentity))
    entityDF_dynamo = spark.createDataFrame(entityDF_dynamo_rdd, dynamo_obj.dynamoDB_schema)    
    entityDF_dynamo_fn = dynamo_obj.dynamotablebuild(entityDF_dynamo, entityDF, attributeCol, uniqueCol, targetentity)
    #entityDF_dynamo_fn.coalesce(1).write.format("json").mode("overwrite").save("s3://deduptestbucket/MDS_test/"+entity+"/")
    print('entityDF_dynamo_count', entityDF_dynamo_fn.count())
    payload_dynamo_write = entityDF_dynamo_fn.drop_duplicates().toJSON().map(lambda j:json.loads(j)).collect()
    for drow in payload_dynamo_write:
        with dynamotable.batch_writer() as batch:
            batch.put_item(Item=drow)


config = Configuration()
entities = config.fetch_run_config()
for entity,config in entities.items():
    sourceentity = config.get('sourceentity')
    targetentity = config.get('entity')
    dynamotable = dynamodb.Table(config.get('indexTable'))
    uniqueCol = config.get('uniqueCol')
    attributeCol = config.get('attributeCol')
    dynamo_obj = DynamoIndexBuilder()
    year = config.get('year')
    defaultstartDate = year+'-01-01'
    defaultendDate = datetime.now(timezone('Asia/Kolkata')).strftime('%Y-%m-%d')
    startDate = config.get('startDate') if config.get('startDate') != '' else defaultstartDate
    endDate = config.get('endDate') if config.get('endDate') != '' else defaultendDate
    processEntity(s3BucketName, sourceentity, targetentity, dynamotable, uniqueCol, attributeCol, year, startDate, endDate)
    
